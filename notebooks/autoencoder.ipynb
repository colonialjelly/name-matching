{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distant-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from matchers import constant, dataset, metrics, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removed-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAME_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-corrections",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names, relevant_names, all_candidates = dataset.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-camel",
   "metadata": {},
   "source": [
    "### Build token index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spare-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx_map, idx_to_char_map = utils.build_token_idx_maps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-spare",
   "metadata": {},
   "source": [
    "### Convert names to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colored-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_candidates = utils.convert_names_to_ids(all_candidates, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "X_all_candidates = utils.one_hot_encode(X_all_candidates, constant.VOCAB_SIZE + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-choice",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "annoying-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_input = tf.keras.layers.Input(shape=(MAX_NAME_LENGTH, constant.VOCAB_SIZE + 1))\n",
    "encoder_output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_dim, \n",
    "                                                                    return_sequences=False), \n",
    "                                               name='encoder')(encoder_input)\n",
    "# Decoder\n",
    "h = tf.keras.layers.RepeatVector(MAX_NAME_LENGTH)(encoder_output)\n",
    "h = tf.keras.layers.LSTM(hidden_dim, return_sequences=True)(h)\n",
    "decoder_output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(constant.VOCAB_SIZE + 1, \n",
    "                                                                       activation='softmax'))(h)\n",
    "\n",
    "# Model\n",
    "autoencoder = tf.keras.models.Model(encoder_input, decoder_output)\n",
    "autoencoder.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Model for just the encoder\n",
    "# Used after the autoencoder is fully trained\n",
    "encoder_model = tf.keras.models.Model(inputs=autoencoder.inputs, \n",
    "                                      outputs=autoencoder.get_layer('encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collected-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30, 29)]          0         \n",
      "_________________________________________________________________\n",
      "encoder (Bidirectional)      (None, 200)               104000    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 30, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 100)           120400    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 30, 29)            2929      \n",
      "=================================================================\n",
      "Total params: 227,329\n",
      "Trainable params: 227,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "focal-puzzle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 19s 326ms/step - loss: 2.0195\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 19s 399ms/step - loss: 1.0181\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 20s 413ms/step - loss: 0.9040\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.8523\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 18s 371ms/step - loss: 0.7779\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 18s 377ms/step - loss: 0.7414\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 18s 368ms/step - loss: 0.7707\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 0.6823\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 18s 383ms/step - loss: 0.6427\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 0.6640\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 18s 381ms/step - loss: 0.6230\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 18s 370ms/step - loss: 0.5911\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 18s 376ms/step - loss: 0.5695\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 16s 342ms/step - loss: 0.5491\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 16s 342ms/step - loss: 0.5326\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 17s 345ms/step - loss: 0.5142\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 17s 346ms/step - loss: 0.5378\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 0.4901\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 18s 379ms/step - loss: 0.4687\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 17s 363ms/step - loss: 0.4506\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 0.4336\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 0.4167\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 17s 344ms/step - loss: 0.4167\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 18s 381ms/step - loss: 0.4163\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.3827\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 17s 346ms/step - loss: 0.3682\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 18s 381ms/step - loss: 0.3575\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 19s 397ms/step - loss: 0.3434\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 18s 370ms/step - loss: 0.3329\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 18s 375ms/step - loss: 0.3214\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 17s 358ms/step - loss: 0.3385\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 18s 384ms/step - loss: 0.3504\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 18s 375ms/step - loss: 0.3014\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 20s 408ms/step - loss: 0.2865\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 19s 396ms/step - loss: 0.2770\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 16s 344ms/step - loss: 0.2669\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 17s 349ms/step - loss: 0.2567\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 17s 345ms/step - loss: 0.2493\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 16s 339ms/step - loss: 0.2416\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 16s 344ms/step - loss: 0.2321\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 17s 348ms/step - loss: 0.2248\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.2166\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 17s 357ms/step - loss: 0.2085\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 18s 369ms/step - loss: 0.2415\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 18s 377ms/step - loss: 0.3171\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 19s 393ms/step - loss: 0.2121\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.1962\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 19s 386ms/step - loss: 0.1862\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 17s 346ms/step - loss: 0.1820\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 17s 346ms/step - loss: 0.1767\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 19s 407ms/step - loss: 0.1704\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 18s 365ms/step - loss: 0.1642\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 16s 343ms/step - loss: 0.1607\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.1538\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 0.1478\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 17s 356ms/step - loss: 0.1452\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 23s 474ms/step - loss: 0.1414\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 18s 382ms/step - loss: 0.1353\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 19s 393ms/step - loss: 0.1294\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 19s 401ms/step - loss: 0.1250\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1199\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.1160\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 18s 377ms/step - loss: 0.1108\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 17s 351ms/step - loss: 0.1113\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 18s 374ms/step - loss: 0.3790\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 0.1286\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 19s 395ms/step - loss: 0.1107\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 0.1029\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 18s 375ms/step - loss: 0.0955\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.0932\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 17s 359ms/step - loss: 0.0897\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 17s 348ms/step - loss: 0.0859\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 16s 338ms/step - loss: 0.0832\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 16s 333ms/step - loss: 0.0798\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 17s 356ms/step - loss: 0.0768\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.0751\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 16s 324ms/step - loss: 0.0724\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 18s 383ms/step - loss: 0.0698\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 19s 391ms/step - loss: 0.0673\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 18s 367ms/step - loss: 0.0655\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 18s 372ms/step - loss: 0.0642\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 16s 325ms/step - loss: 0.0611\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 17s 345ms/step - loss: 0.0591\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 19s 402ms/step - loss: 0.0571\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 16s 334ms/step - loss: 0.0550\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 16s 328ms/step - loss: 0.0538\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 18s 378ms/step - loss: 0.0527\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 16s 336ms/step - loss: 0.0502\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 19s 387ms/step - loss: 0.0482\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 16s 334ms/step - loss: 0.0467\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 18s 370ms/step - loss: 0.0465\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 16s 337ms/step - loss: 0.0447\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 18s 378ms/step - loss: 0.0430\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 16s 326ms/step - loss: 0.0415\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 16s 326ms/step - loss: 0.0395\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 16s 324ms/step - loss: 0.0386\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 18s 372ms/step - loss: 0.0379\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 16s 327ms/step - loss: 0.0370\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 16s 324ms/step - loss: 0.0359\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 16s 335ms/step - loss: 0.0339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1675c3610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_all_candidates, \n",
    "                X_all_candidates, \n",
    "                epochs=100,\n",
    "                batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-department",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "retired-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_names = utils.convert_names_to_ids(input_names, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "X_input_names = utils.one_hot_encode(X_input_names, constant.VOCAB_SIZE + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "offshore-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_names_encoded = encoder_model.predict(X_input_names)\n",
    "X_candidates_encoded = encoder_model.predict(X_all_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "contemporary-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = utils.get_candidates_batch(X_input_names_encoded, \n",
    "                                        X_candidates_encoded, \n",
    "                                        all_candidates,\n",
    "                                        num_candidates=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hungry-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names = candidates[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-central",
   "metadata": {},
   "source": [
    "### mAP @ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "banned-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117225590367576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_avg_precision_k(relevant_names, candidate_names, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-boston",
   "metadata": {},
   "source": [
    "### mAP @ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rolled-maryland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4140840293381946"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_avg_precision_k(relevant_names, candidate_names, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-slope",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "boring-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['<schumacker>', 0.9707528352737427],\n",
       "        ['<stelmacher>', 0.9584547877311707],\n",
       "        ['<schumaker>', 0.9551969766616821],\n",
       "        ['<schurhamer>', 0.9541249871253967],\n",
       "        ['<stillmacher>', 0.9501252770423889],\n",
       "        ['<schacher>', 0.9501103162765503],\n",
       "        ['<schmelcher>', 0.9477940797805786],\n",
       "        ['<schumpert>', 0.9368616342544556],\n",
       "        ['<schmicker>', 0.9283653497695923],\n",
       "        ['<standacher>', 0.9281593561172485]]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_name = ['<schumacher>']\n",
    "test_name_sequence = utils.convert_names_to_ids(test_name, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "test_name_one_hot = utils.one_hot_encode(test_name_sequence, constant.VOCAB_SIZE + 1)\n",
    "test_name_embedding = encoder_model.predict(test_name_one_hot)\n",
    "\n",
    "utils.get_candidates_batch(test_name_embedding, \n",
    "                           X_candidates_encoded,\n",
    "                           all_candidates,\n",
    "                           num_candidates=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-brave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:name-matching] *",
   "language": "python",
   "name": "conda-env-name-matching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
